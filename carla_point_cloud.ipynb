{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 7.17216773,  1.56518707,  3.56518707],\n       [ 7.17091603,  1.540074  ,  3.56491391],\n       [ 7.16966433,  1.51496961,  3.56464075],\n       ...,\n       [ 8.39936783, -1.80390455,  0.13790498],\n       [ 8.39936783, -1.83299978,  0.13790498],\n       [ 8.39936783, -1.86209502,  0.13790498]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./patch_points_cloud.npy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud('o3d_world_points_cloud.pcd')\n",
    "pcd_patch = o3d.io.read_point_cloud('o3d_patch_points_cloud.pcd')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_patch_data(file_path: str):\n",
    "    patch = torch.load(file_path, map_location='cpu')\n",
    "\n",
    "    return patch.permute((1, 2, 0)).detach().numpy()\n",
    "\n",
    "patch = get_patch_data('../patch.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "# from pyntcloud import PyntCloud\n",
    "\n",
    "# points = pos_3d[:3].numpy().reshape((-1, 3), order='F')\n",
    "# points = point_clouds[81][:3].transpose()\n",
    "# point_cloud.farthest_point_down_sample(num_samples=1000)\n",
    "o3d.visualization.draw_geometries([pcd_patch, pcd])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import queue\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "from numpy.matlib import repmat\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "# from image_converter import *\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def to_bgra_array(image):\n",
    "    \"\"\"Convert a CARLA raw image to a BGRA numpy array.\"\"\"\n",
    "    if not isinstance(image, carla.Image):\n",
    "        raise ValueError(\"Argument must be a carla.sensor.Image\")\n",
    "    array = numpy.frombuffer(image.raw_data, dtype=numpy.dtype(\"uint8\"))\n",
    "    array = numpy.reshape(array, (image.height, image.width, 4))\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "def depth_to_array(image):\n",
    "    \"\"\"\n",
    "    Convert an image containing CARLA encoded depth-map to a 2D array containing\n",
    "    the depth value of each pixel normalized between [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    array = to_bgra_array(image)\n",
    "    array = array.astype(numpy.float32)\n",
    "    # Apply (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1).\n",
    "    normalized_depth = numpy.dot(array[:, :, :3], [65536.0, 256.0, 1.0])\n",
    "    normalized_depth /= 16777215.0  # (256.0 * 256.0 * 256.0 - 1.0)\n",
    "\n",
    "    return normalized_depth\n",
    "\n",
    "\n",
    "def depth_to_local_point_cloud(image, color=None, max_depth=0.9):\n",
    "    \"\"\"\n",
    "    Convert an image containing CARLA encoded depth-map to a 2D array containing\n",
    "    the 3D position (relative to the camera) of each pixel and its corresponding\n",
    "    RGB color of an array.\n",
    "    \"max_depth\" is used to omit the points that are far enough.\n",
    "    \"\"\"\n",
    "    far = 1000.0  # max depth in meters.\n",
    "    normalized_depth = depth_to_array(image)\n",
    "\n",
    "    # (Intrinsic) K Matrix\n",
    "    k = numpy.identity(3)\n",
    "    k[0, 2] = image.width / 2.0\n",
    "    k[1, 2] = image.height / 2.0\n",
    "    k[0, 0] = k[1, 1] = image.width / (2.0 * math.tan(image.fov * math.pi / 360.0))\n",
    "\n",
    "    # 2d pixel coordinates\n",
    "    pixel_length = image.width * image.height\n",
    "    u_coord = repmat(numpy.r_[image.width-1:-1:-1],\n",
    "                     image.height, 1).reshape(pixel_length)\n",
    "    v_coord = repmat(numpy.c_[image.height-1:-1:-1],\n",
    "                     1, image.width).reshape(pixel_length)\n",
    "    if color is not None:\n",
    "        color = color.reshape(pixel_length, 3)\n",
    "    normalized_depth = numpy.reshape(normalized_depth, pixel_length)\n",
    "\n",
    "    # Search for pixels where the depth is greater than max_depth to\n",
    "    # delete them\n",
    "    max_depth_indexes = numpy.where(normalized_depth > max_depth)\n",
    "    normalized_depth = numpy.delete(normalized_depth, max_depth_indexes)\n",
    "    u_coord = numpy.delete(u_coord, max_depth_indexes)\n",
    "    v_coord = numpy.delete(v_coord, max_depth_indexes)\n",
    "    if color is not None:\n",
    "        color = numpy.delete(color, max_depth_indexes, axis=0)\n",
    "\n",
    "    # pd2 = [u,v,1]\n",
    "    p2d = numpy.array([u_coord, v_coord, numpy.ones_like(u_coord)])\n",
    "\n",
    "    # P = [X,Y,Z]\n",
    "    p3d = numpy.dot(numpy.linalg.inv(k), p2d)\n",
    "\n",
    "    p3d *= normalized_depth * far\n",
    "    p3d = numpy.concatenate((p3d, numpy.ones((1, p3d.shape[1]))))\n",
    "\n",
    "    return p3d, color\n",
    "\n",
    "\n",
    "def get_camera2world_matrix(carla_transform: carla.Transform, real_y_axis=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        carla_transform: Carla.Transform instance, contains carla.Location and carla.Rotation\n",
    "        real_y_axis: return real y-axis value when setting true. but the view of point cloud in open-3d\n",
    "            will be reversed in yaw direction.\n",
    "    Returns:\n",
    "        a 4x4 rotation & transaction matrix that transforms coords from camera coord-sys to simu-world coord-sys.\n",
    "    \"\"\"\n",
    "    camera2vehicle_matrix = np.array([[0, 0, 1, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    pitch = carla_transform.rotation.pitch / 180.0 * math.pi\n",
    "    yaw = carla_transform.rotation.yaw / 180.0 * math.pi\n",
    "    roll = carla_transform.rotation.roll / 180.0 * math.pi\n",
    "    loc_x = carla_transform.location.x\n",
    "    loc_y = - carla_transform.location.y\n",
    "    loc_z = carla_transform.location.z\n",
    "    sin_y, sin_p, sin_r = math.sin(yaw), math.sin(pitch), math.sin(roll)\n",
    "    cos_y, cos_p, cos_r = math.cos(yaw), math.cos(pitch), math.cos(roll)\n",
    "\n",
    "    vehicle2world_matrix = np.array([\n",
    "        [cos_y * cos_p, cos_y * sin_p * sin_r + sin_y * cos_r, - cos_y * sin_p * cos_r + sin_y * sin_r, loc_x],\n",
    "        [-sin_y * cos_p, - sin_y * sin_p * sin_r + cos_y * cos_r, sin_y * sin_p * cos_r + cos_y * sin_r, loc_y],\n",
    "        [sin_p, -cos_p * sin_r, cos_p * cos_r, loc_z],\n",
    "        [0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    if real_y_axis:\n",
    "        vehicle2world_matrix[1] *= -1\n",
    "\n",
    "    return vehicle2world_matrix @ camera2vehicle_matrix\n",
    "\n",
    "\n",
    "def generate_lidar_bp(blueprint_library, delta):\n",
    "    \"\"\"\n",
    "    To get lidar bp\n",
    "    :param blueprint_library: the world blueprint_library\n",
    "    :param delta: update rate(s)\n",
    "    :return: lidar bp\n",
    "    \"\"\"\n",
    "    lidar_bp = blueprint_library.find(\"sensor.lidar.ray_cast\")\n",
    "    lidar_bp.set_attribute(\"dropoff_general_rate\", \"0.0\")\n",
    "    lidar_bp.set_attribute(\"dropoff_intensity_limit\", \"1.0\")\n",
    "    lidar_bp.set_attribute(\"dropoff_zero_intensity\", \"0.0\")\n",
    "\n",
    "    lidar_bp.set_attribute(\"upper_fov\", str(15.0))\n",
    "    lidar_bp.set_attribute(\"lower_fov\", str(-25.0))\n",
    "    lidar_bp.set_attribute(\"channels\", str(64.0))\n",
    "    lidar_bp.set_attribute(\"range\", str(100.0))\n",
    "    lidar_bp.set_attribute(\"rotation_frequency\", str(1.0 / delta))\n",
    "    lidar_bp.set_attribute(\"points_per_second\", str(500000))\n",
    "\n",
    "    return lidar_bp\n",
    "\n",
    "#连接Carla并获取世界\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "\n",
    "# 生成车辆\n",
    "vehicle_bp =bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_points[0])\n",
    "\n",
    "# 生成相机\n",
    "rgb_camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "rgb_camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "rgb_camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "rgb_camera = world.spawn_actor(rgb_camera_bp, rgb_camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "depth_camera_bp = bp_lib.find('sensor.camera.depth')\n",
    "depth_camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "depth_camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "depth_camera = world.spawn_actor(depth_camera_bp, depth_camera_init_trans, attach_to=vehicle, attachment_type=carla.AttachmentType.Rigid)\n",
    "\n",
    "lidar_bp = generate_lidar_bp(bp_lib, delta=0.05)\n",
    "lidar_camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "lidar_camera = world.spawn_actor(depth_camera_bp, lidar_camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# 设置traffic manager\n",
    "tm = client.get_trafficmanager(8000)\n",
    "tm.set_synchronous_mode(True)\n",
    "# 是否忽略红绿灯\n",
    "tm.ignore_lights_percentage(vehicle, 100)\n",
    "# 如果限速30km/h -> 30*(1-10%)=27km/h\n",
    "# tm.global_percentage_speed_difference(10.0)\n",
    "\n",
    "\n",
    "# 设置自动驾驶\n",
    "# vehicle.set_autopilot(True)\n",
    "vehicle.set_autopilot(True, tm.get_port())\n",
    "\n",
    "# 设置仿真模式为同步模式\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # 启用同步模式\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# 创建对接接收相机数据\n",
    "depth_image_queue = queue.Queue()\n",
    "depth_camera.listen(depth_image_queue.put)\n",
    "\n",
    "rgb_image_queue = queue.Queue()\n",
    "rgb_camera.listen(rgb_image_queue.put)\n",
    "\n",
    "lidar_queue = queue.Queue()\n",
    "lidar_camera.listen(lidar_queue.put)\n",
    "\n",
    "# 从相机获取属性\n",
    "image_w = rgb_camera_bp.get_attribute(\"image_size_x\").as_int()  # 图像宽度\n",
    "image_h = rgb_camera_bp.get_attribute(\"image_size_y\").as_int()  # 图像高度\n",
    "fov = rgb_camera_bp.get_attribute(\"fov\").as_float()  # 视场角\n",
    "\n",
    "\n",
    "# 获取第一张图像\n",
    "world.tick()\n",
    "depth_image = depth_image_queue.get()\n",
    "rgb_image = rgb_image_queue.get()\n",
    "# 将原始数据重新整形为 RGB 数组\n",
    "rgb_img = np.reshape(np.copy(rgb_image.raw_data), (rgb_image.height, rgb_image.width, 4))\n",
    "\n",
    "# 在 OpenCV 的显示窗口中显示图像\n",
    "cv2.namedWindow('ImageWindowName', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('ImageWindowName', rgb_img)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "point_clouds = []\n",
    "colors = []\n",
    "\n",
    "idx = -1\n",
    "\n",
    "prj_config = []\n",
    "\n",
    "while True:\n",
    "    # 更新世界状态并获取图像\n",
    "    world.tick()\n",
    "    idx += 1\n",
    "\n",
    "    depth_image = depth_image_queue.get()\n",
    "    rgb_image = rgb_image_queue.get()\n",
    "    rgb_image = np.reshape(np.copy(rgb_image.raw_data), (rgb_image.height, rgb_image.width, 4))\n",
    "\n",
    "    lidar_data = lidar_queue.get()\n",
    "\n",
    "    if idx % 40 == 0:\n",
    "\n",
    "        # Tvc_matrix = np.array([[0, 0, 1, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1]])\n",
    "        Tvc_matrix = np.array([[0, 0, 1, 0], [1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 0, 1]])\n",
    "        # Tvc_matrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "        # transform = depth_camera.get_transform()\n",
    "        #\n",
    "        # pitch = transform.rotation.pitch / 180.0 * math.pi\n",
    "        # yaw = transform.rotation.yaw / 180.0 * math.pi\n",
    "        # roll = transform.rotation.roll / 180.0 * math.pi\n",
    "        # loc_x, loc_y, loc_z = transform.location.x, - transform.location.y, transform.location.z\n",
    "        # sin_y, sin_p, sin_r = math.sin(yaw), math.sin(pitch), math.sin(roll)\n",
    "        # cos_y, cos_p, cos_r = math.cos(yaw), math.cos(pitch), math.cos(roll)\n",
    "        #\n",
    "        # camera_to_world = np.array(\n",
    "        #     [[cos_y * cos_p, cos_y * sin_p * sin_r + sin_y * cos_r, - cos_y * sin_p * cos_r + sin_y * sin_r, loc_x],\n",
    "        #      [-sin_y * cos_p, - sin_y * sin_p * sin_r + cos_y * cos_r, sin_y * sin_p * cos_r + cos_y * sin_r, loc_y],\n",
    "        #      [sin_p, -cos_p * sin_r, cos_p * cos_r, loc_z],\n",
    "        #      [0, 0, 0, 1]]\n",
    "        # )\n",
    "\n",
    "        # rx = np.array([\n",
    "        #     [1, 0, 0], [0, math.cos(roll), - math.sin(roll)], [0, math.sin(roll), math.cos(roll)],\n",
    "        # ], dtype=np.float64)\n",
    "        # ry = np.array([\n",
    "        #     [math.cos(pitch), 0, math.sin(pitch)], [0, 1, 0], [- math.sin(pitch), 0, math.cos(pitch)]\n",
    "        # ], dtype=np.float64)\n",
    "        # rz = np.array([\n",
    "        #     [math.cos(yaw), - math.sin(yaw), 0], [math.sin(yaw),  math.cos(yaw), 0], [0, 0, 1]\n",
    "        # ], dtype=np.float64)\n",
    "\n",
    "        # mat = transform.get_matrix()\n",
    "        # x, y, z = depth_camera.get_transform().location.x, - depth_camera.get_transform().location.y, depth_camera.get_transform().location.z\n",
    "        # yaw, pitch, roll = - depth_camera.get_transform().rotation.yaw, - depth_camera.get_transform().rotation.pitch, - depth_camera.get_transform().rotation.roll\n",
    "        # transform = carla.Transform(carla.Location(x=x, y=y, z=z), carla.Rotation(yaw=yaw, pitch=pitch, roll=roll))\n",
    "        # mat = transform.get_matrix()\n",
    "\n",
    "        p3d, color = depth_to_local_point_cloud(depth_image, rgb_image[:, :, :3], max_depth=0.8)\n",
    "\n",
    "        # p3d = camera_to_world @ Tvc_matrix @ p3d[:3] + np.array([[loc_x], [loc_y], [loc_z]])\n",
    "        # camera_to_world[1] *= -1\n",
    "        # p3d = (camera_to_world @ Tvc_matrix @ p3d)[:3]\n",
    "        mat = get_camera2world_matrix(depth_camera.get_transform())\n",
    "\n",
    "        p3d = mat @ p3d\n",
    "\n",
    "        # print('car pos:', (depth_camera.get_transform().location.x, depth_camera.get_transform().location.y, depth_camera.get_transform().location.z))\n",
    "        # print('pix pos:', p3d[:, 0])\n",
    "        # p3d = rz @ ry @ rx @ (Tvc_matrix @ p3d)[:3] + np.array([[loc_x], [loc_y], [loc_z]])\n",
    "\n",
    "        point_clouds.append(p3d[:3])\n",
    "        colors.append(color)\n",
    "\n",
    "    cv2.imshow('ImageWindowName', rgb_image)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "depth_camera.destroy()\n",
    "rgb_camera.destroy()\n",
    "lidar_camera.destroy()\n",
    "vehicle.destroy()\n",
    "depth_image_queue.queue.clear()\n",
    "rgb_image_queue.queue.clear()\n",
    "lidar_queue.queue.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24076\\591528047.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbroadcast_to\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdepth_to_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprj_config\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m600\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m800\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m600\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m800\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m255.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "np.array(np.broadcast_to(depth_to_array(prj_config[0]).reshape(600, 800, 1), (600, 800, 3)) * 255.0, dtype=np.uint8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $轴的逆变换：\\begin{bmatrix}\\ 0 & 0 & 1 & 0\\\\ 1 & 0 & 0 & 0\\\\ 0 & -1 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $ ##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# $\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "x^{'} \\\\ y^{'} \\\\ z^{'}\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_{0} \\\\ y_{0} \\\\ z_{0}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "cos(-yaw) & -sin(-yaw) & 0\n",
    "\\\\ sin(-yaw) & cos(-yaw) & 0\n",
    "\\\\ 0 & 0 & 1\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "cos(-pitch) & 0 & sin(-pitch)\n",
    "\\\\ 0 & 1 & 0\n",
    "\\\\ -sin(-pitch) & 0 & cos(-pitch)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0\n",
    "\\\\ 0 & cos(-roll) & -sin(-roll)\n",
    "\\\\ 0 & sin(-roll) & cos(-roll)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\ y \\\\ z\n",
    "\\end{bmatrix} \\\\\n",
    "\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_{0} \\\\ y_{0} \\\\ z_{0}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "cos(y)cos(p) & cos(y)sin(p)sin(r) + sin(y)cos(r) & -cos(y)sin(p)cos(r)+sin(y)sin(r)\n",
    "\\\\-sin(y)cos(p) & -sin(y)sin(p)sin(r)+cos(y)cos(r) & sin(y)sin(p)cos(r)+cos(y)sin(r)\n",
    "\\\\ sin(p) & -cos(p)sin(r) & cos(p)cos(r)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\ y \\\\ z\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$\n",
    "# $\n",
    "\\iff\n",
    "\\begin{bmatrix}\n",
    "x^{'} \\\\ y^{'} \\\\ z^{'} \\\\ 1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "c_y \\cdot c_p & c_y \\cdot s_p \\cdot s_r + s_y \\cdot c_r & - c_y \\cdot s_p \\cdot c_r + s_y \\cdot s_r & x_{0}\n",
    "\\\\-s_y \\cdot c_p & -s_y \\cdot s_p \\cdot s_r + c_y \\cdot c_r & s_y \\cdot s_p \\cdot c_r + c_y \\cdot s_r & y_{0}\n",
    "\\\\ s_p & -c_p \\cdot s_r & c_p \\cdot c_r & z_{0}\n",
    "\\\\ 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\ y \\\\ z \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# $\n",
    "\\begin{bmatrix}\n",
    "x_{global} \\\\ -y_{global} \\\\ z_{global}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "cos(-yaw) & -sin(-yaw) & 0\n",
    "\\\\ sin(-yaw) & cos(-yaw) & 0\n",
    "\\\\ 0 & 0 & 1\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "cos(-pitch) & 0 & sin(-pitch)\n",
    "\\\\ 0 & 1 & 0\n",
    "\\\\ -sin(-pitch) & 0 & cos(-pitch)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0\n",
    "\\\\ 0 & cos(-roll) & -sin(-roll)\n",
    "\\\\ 0 & sin(-roll) & cos(-roll)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 1\n",
    "\\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{camera} \\\\ y_{camera} \\\\ z_{camera}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x_{global} + x_{camera} \\cdot cos(y)cos(p) + y_{camera} \\cdot (cos(y)sin(p)sin(r) + sin(y)cos(r)) + z_{camera} \\cdot (-cos(y)sin(p)cos(r)+sin(y)sin(r))\n",
    "\\\\ -y_{global} + x_{camera} \\cdot -sin(y)cos(p) + y_{camera} \\cdot (-sin(y)sin(p)sin(r)+cos(y)cos(r)) + z_{camera} \\cdot (sin(y)sin(p)cos(r)+cos(y)sin(r))\n",
    "\\\\ z_{global} + x_{camera} \\cdot sin(p) + y_{camera} \\cdot (-cos(p)sin(r)) + z_{camera} \\cdot (cos(p)cos(r))\n",
    "\\end{bmatrix}\n",
    "$ #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prj_config[1].x, prj_config[1].y, prj_config[1].z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p3d[:, 6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prj_patch2point_cloud(depth_data: carla.Image, patch_data: numpy.ndarray, camera_location: carla.Location, camera_rotation: carla.Rotation, max_depth=0.9, min_depth=0.0):\n",
    "    depth_array = depth_to_array(depth_data)\n",
    "\n",
    "    far = 1000.0\n",
    "    k = numpy.identity(3)\n",
    "    cw, ch = depth_data.width / 2.0, depth_data.height / 2.0\n",
    "    k[0, 2], k[1, 2] = cw, ch\n",
    "    k[0, 0] = k[1, 1] = depth_data.width / (2.0 * math.tan(depth_data.fov * math.pi / 360.0))\n",
    "\n",
    "    print(depth_array.shape)\n",
    "    # patch_depth = depth_array[\n",
    "    #               int(ch) - patch_data.shape[0] // 2: int(ch) - patch_data.shape[0] // 2 + patch_data.shape[0],\n",
    "    #               int(cw) - patch_data.shape[1] // 2: int(cw) - patch_data.shape[1] // 2 + patch_data.shape[1]]\n",
    "    patch_depth = depth_array[\n",
    "              0 : patch_data.shape[0],\n",
    "              0 : patch_data.shape[1]]\n",
    "\n",
    "    pixel_length = patch_data.shape[0] * patch_data.shape[1]\n",
    "    u_coord = repmat(numpy.r_[patch_data.shape[1] - 1:-1:-1], patch_data.shape[0], 1).reshape(pixel_length)\n",
    "    v_coord = repmat(numpy.c_[patch_data.shape[0] - 1:-1:-1], 1, patch_data.shape[1]).reshape(pixel_length)\n",
    "\n",
    "    color = patch_data.reshape(pixel_length, 3)\n",
    "    normalized_depth = numpy.reshape(patch_depth, pixel_length)\n",
    "\n",
    "    # Search for pixels where the depth is greater than max_depth to\n",
    "    # delete them\n",
    "    max_depth_indexes = numpy.where(normalized_depth > max_depth)\n",
    "    normalized_depth = numpy.delete(normalized_depth, max_depth_indexes)\n",
    "    u_coord = numpy.delete(u_coord, max_depth_indexes)\n",
    "    v_coord = numpy.delete(v_coord, max_depth_indexes)\n",
    "    if color is not None:\n",
    "        color = numpy.delete(color, max_depth_indexes, axis=0)\n",
    "\n",
    "    # pd2 = [u,v,1]\n",
    "    p2d = numpy.array([u_coord, v_coord, numpy.ones_like(u_coord)])\n",
    "\n",
    "    # P = [X,Y,Z]\n",
    "    p3d = numpy.dot(numpy.linalg.inv(k), p2d)\n",
    "\n",
    "    p3d *= normalized_depth * far\n",
    "    p3d = numpy.concatenate((p3d, numpy.ones((1, p3d.shape[1]))))\n",
    "\n",
    "    Tvc_matrix = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "    pitch = camera_rotation.pitch / 180.0 * math.pi\n",
    "    yaw = camera_rotation.yaw / 180.0 * math.pi\n",
    "    roll = camera_rotation.roll / 180.0 * math.pi\n",
    "    loc_x, loc_y, loc_z = camera_location.x, - camera_location.y, camera_location.z\n",
    "    sin_y, sin_p, sin_r = math.sin(yaw), math.sin(pitch), math.sin(roll)\n",
    "    cos_y, cos_p, cos_r = math.cos(yaw), math.cos(pitch), math.cos(roll)\n",
    "\n",
    "    camera_to_world = np.array(\n",
    "        [[cos_y * cos_p, cos_y * sin_p * sin_r + sin_y * cos_r, - cos_y * sin_p * cos_r + sin_y * sin_r],\n",
    "         [-sin_y * cos_p, - sin_y * sin_p * sin_r + cos_y * cos_r, sin_y * sin_p * cos_r + cos_y * sin_r],\n",
    "         [sin_p, -cos_p * sin_r, cos_p * cos_r]]\n",
    "    )\n",
    "\n",
    "    p3d = camera_to_world @ Tvc_matrix @ p3d[:3] + np.array([[loc_x], [loc_y], [loc_z]])\n",
    "\n",
    "    return p3d, color"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv2.imshow('cc', depth_to_array(prj_config[0]) * 255)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# To acquire point cloud and display it with open3d\n",
    "#####################################################\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import carla\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "\n",
    "VIDIDIS = np.array(cm.get_cmap(\"plasma\").colors)\n",
    "VID_RANGE = np.linspace(0.0, 1.0, VIDIDIS.shape[0])\n",
    "\n",
    "def generate_lidar_bp(blueprint_library, delta):\n",
    "    \"\"\"\n",
    "    To get lidar bp\n",
    "    :param blueprint_library: the world blueprint_library\n",
    "    :param delta: update rate(s)\n",
    "    :return: lidar bp\n",
    "    \"\"\"\n",
    "    lidar_bp = blueprint_library.find(\"sensor.lidar.ray_cast\")\n",
    "    lidar_bp.set_attribute(\"dropoff_general_rate\", \"0.0\")\n",
    "    lidar_bp.set_attribute(\"dropoff_intensity_limit\", \"1.0\")\n",
    "    lidar_bp.set_attribute(\"dropoff_zero_intensity\", \"0.0\")\n",
    "\n",
    "    lidar_bp.set_attribute(\"upper_fov\", str(15.0))\n",
    "    lidar_bp.set_attribute(\"lower_fov\", str(-25.0))\n",
    "    lidar_bp.set_attribute(\"channels\", str(64.0))\n",
    "    lidar_bp.set_attribute(\"range\", str(100.0))\n",
    "    lidar_bp.set_attribute(\"rotation_frequency\", str(1.0 / delta))\n",
    "    lidar_bp.set_attribute(\"points_per_second\", str(500000))\n",
    "\n",
    "    return lidar_bp\n",
    "\n",
    "\n",
    "def lidar_callback(point_cloud, point_list):\n",
    "    # We need to convert point cloud(carla-format) into numpy.ndarray\n",
    "    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype = np.dtype(\"f4\")))\n",
    "    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n",
    "\n",
    "    intensity = data[:, -1]\n",
    "    intensity_col = 1.0 - np.log(intensity) / np.log(np.exp(-0.004 * 100))\n",
    "    int_color = np.c_[\n",
    "        np.interp(intensity_col, VID_RANGE, VIDIDIS[:, 0]),\n",
    "        np.interp(intensity_col, VID_RANGE, VIDIDIS[:, 1]),\n",
    "        np.interp(intensity_col, VID_RANGE, VIDIDIS[:, 2])]\n",
    "\n",
    "    points = data[:, :-1] # we only use x, y, z coordinates\n",
    "    points[:, 1] = -points[:, 1] # This is different from official script\n",
    "    point_list.points = o3d.utility.Vector3dVector(points)\n",
    "    point_list.colors = o3d.utility.Vector3dVector(int_color)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Let's show point cloud with open3d in carla!\")\n",
    "    client = carla.Client(\"127.0.0.1\", 2000)\n",
    "    client.set_timeout(2.0)\n",
    "    world = client.get_world()\n",
    "\n",
    "    try:\n",
    "        # 1. To do some synchronous settings in world\n",
    "        original_settings = world.get_settings()\n",
    "        settings = world.get_settings()\n",
    "        traffic_manager = client.get_trafficmanager(8000)\n",
    "        traffic_manager.set_synchronous_mode(True)\n",
    "\n",
    "        delta = 0.05\n",
    "\n",
    "        settings.fixed_delta_seconds = delta\n",
    "        settings.synchronous_mode = True\n",
    "        # settings.no_rendering_mode = True\n",
    "        world.apply_settings(settings)\n",
    "\n",
    "        # 2. To get blueprint for your ego vehicle and spawn it!\n",
    "        blueprint_library = world.get_blueprint_library()\n",
    "        vehicle_bp = blueprint_library.filter(\"model3\")[0]\n",
    "        vehicle_transform = random.choice(world.get_map().get_spawn_points())\n",
    "        vehicle = world.spawn_actor(vehicle_bp, vehicle_transform)\n",
    "        vehicle.set_autopilot(True)\n",
    "\n",
    "        # 3. To get lidar blueprint and spawn it on your car!\n",
    "        lidar_bp = generate_lidar_bp(blueprint_library, delta)\n",
    "        lidar_transform = carla.Transform(carla.Location(x = -0.5, z = 1.8))\n",
    "        lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to = vehicle)\n",
    "\n",
    "        # 4. We set a point_list to store our point cloud\n",
    "        point_list = o3d.geometry.PointCloud()\n",
    "\n",
    "        # 5. Listen to the lidar to collect point cloud\n",
    "        lidar.listen(lambda data: lidar_callback(data, point_list))\n",
    "\n",
    "        # 6. We set some basic settings for display with open3d\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window(\n",
    "            window_name= \"Display Point Cloud\",\n",
    "            width= 960,\n",
    "            height= 540,\n",
    "            left= 480,\n",
    "            top= 270)\n",
    "\n",
    "        vis.get_render_option().background_color = [0.05, 0.05, 0.05]\n",
    "        vis.get_render_option().point_size = 1\n",
    "        vis.get_render_option().show_coordinate_frame = True\n",
    "\n",
    "        frame = 0\n",
    "        dt0 = datetime.now()\n",
    "\n",
    "        while True:\n",
    "            if frame == 2:\n",
    "                vis.add_geometry(point_list)\n",
    "\n",
    "            vis.update_geometry(point_list)\n",
    "            vis.poll_events()\n",
    "            vis.update_renderer()\n",
    "            time.sleep(0.005)\n",
    "\n",
    "            world.tick()\n",
    "\n",
    "            # We here add a spectator to watch how our ego vehicle will move\n",
    "            spectator = world.get_spectator()\n",
    "            transform = vehicle.get_transform()  # we get the transform of vehicle\n",
    "            spectator.set_transform(carla.Transform(transform.location + carla.Location(z=50),\n",
    "                                                    carla.Rotation(pitch=-90)))\n",
    "\n",
    "            process_time = datetime.now() - dt0\n",
    "            sys.stdout.write(\"\\r\" + \"FPS: \" + str(1.0 / process_time.total_seconds()) + \"Current Frame: \" + str(frame))\n",
    "            sys.stdout.flush()\n",
    "            dt0 = datetime.now()\n",
    "\n",
    "            frame += 1\n",
    "\n",
    "    finally:\n",
    "        world.apply_settings(original_settings)\n",
    "        traffic_manager.set_synchronous_mode(False)\n",
    "        vehicle.destroy()\n",
    "        lidar.destroy()\n",
    "        vis.destroy_window()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 2)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array([[], [], []]), np.array([[1, 2], [2, 3], [3, 4]])], axis=1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([], shape=(3, 0), dtype=float64)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.empty((3, 0), dtype=np.float64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<carla.libcarla.Transform at 0x22f29c7c150>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spawn_points[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from carla_patch import CarlaPatch\n",
    "import torch\n",
    "import numpy as np\n",
    "patch = torch.load('C:/Users/Kai/Desktop/patch.pt', map_location='cpu')\n",
    "carla_patch = CarlaPatch(patch, patch_location=(0, -0, 0), patch_rotation=(70, 60, 40), pixel_length=0.5)\n",
    "patch_data, pos_3d = carla_patch()\n",
    "# pos_3d = pos_3d[:3].transpose(0, 2).reshape(-1, 3).numpy()\n",
    "# patch_data = patch_data.transpose(0, 2).reshape(-1, 3).detach_().numpy()\n",
    "patch_data = patch_data.permute((1, 2, 0)).detach().numpy()\n",
    "# p3d, color = prj_patch2point_cloud(prj_config[0], patch_data, prj_config[1], prj_config[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "# from pyntcloud import PyntCloud\n",
    "\n",
    "# points = pos_3d[:3].numpy().reshape((-1, 3), order='F')\n",
    "points = np.concatenate(point_clouds[0: 2], axis=1)[:3].transpose()\n",
    "points_color = np.concatenate([colors[0], np.zeros_like(colors[1])], axis=0)\n",
    "# points = point_clouds[81][:3].transpose()\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(np.array(points))\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(points_color / 255.0)\n",
    "# point_cloud.farthest_point_down_sample(num_samples=1000)\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p3d[2] *= -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# points = pos_3d[:3].numpy().reshape((-1, 3), order='F')\n",
    "points = np.concatenate(point_clouds[0: 5], axis=1)[:3].transpose()\n",
    "points_color = np.concatenate(colors[0: 5], axis=0)\n",
    "# points = point_clouds[81][:3].transpose()\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(np.array(points))\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(points_color / 255.0)\n",
    "# point_cloud.farthest_point_down_sample(num_samples=1000)\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# points = pos_3d[:3].numpy().reshape((-1, 3), order='F')\n",
    "# points = point_clouds[81][:3].transpose()\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(np.array(p3d).transpose())\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(color)\n",
    "# point_cloud.farthest_point_down_sample(num_samples=1000)\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "points = np.concatenate(point_clouds[:], axis=1)[:3].transpose()\n",
    "points_color = np.concatenate(colors[:], axis=0)\n",
    "pcd = o3d.geometry.PointCloud()#传入3d点云\n",
    "pcd.points = o3d.utility.Vector3dVector(np.array(points))\t#point3D二维numpy矩阵,将其转换为open3d点云格式\n",
    "pcd.colors = o3d.utility.Vector3dVector(points_color / 255.0)\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\t#创建窗口\n",
    "render_option: o3d.visualization.RenderOption = vis.get_render_option()\t#设置点云渲染参数\n",
    "render_option.background_color = np.array([0, 0, 0])\t#设置背景色（这里为黑色）\n",
    "render_option.point_size = 0.5\t#设置渲染点的大小\n",
    "\n",
    "vis.add_geometry(pcd)\t#添加点云\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vis.destroy_window()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
