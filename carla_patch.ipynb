{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-64.64484405517578 24.471010208129883 0.5999999642372131\n"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import random\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "import math\n",
    "# import torchvision.transforms as transforms\n",
    "from typing import *\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class CarlaPatch:\n",
    "    \"\"\"\n",
    "    init parameters:\n",
    "        flat_patch: torch.Tensor or ndarray, with shape (C, H, W)\n",
    "        patch_location: tuple or carla.Location, (x, y, z), e.g. (10, 10.1, 0.6)\n",
    "        patch_rotation: tuple or carla.Rotation, (pitch, yaw, roll), e.g. (30 degrees, 20, 10)\n",
    "        pixel_length: float [对应的是patch的一个像素在仿真世界里对应的长度，这个数值大概多少我还没有概念， 需要尝试一下]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            flat_patch: torch.Tensor or np.ndarray,\n",
    "            patch_location: Tuple or carla.Location,\n",
    "            patch_rotation: Tuple or carla.Rotation,\n",
    "            pixel_length: float = 0.1,\n",
    "            patch_transform: Callable = None\n",
    "\n",
    "    ):\n",
    "        self.flat_patch = flat_patch.cpu() if isinstance(flat_patch, torch.Tensor) else torch.tensor(flat_patch)\n",
    "\n",
    "        self.patch_location = patch_location\n",
    "        self.patch_rotation = patch_rotation\n",
    "        self.pixel_length = pixel_length\n",
    "\n",
    "        self.patch_pos_3d = self._trans_all_dots2pos_3d()\n",
    "\n",
    "    @staticmethod\n",
    "    def _default_patch_trans(patch: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    def _trans_all_dots2pos_3d(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        通过给定的location，rotation和输入的patch，返回每个像素点的坐标，形状是（3， H， W），3对应x, y, z坐标\n",
    "        \"\"\"\n",
    "        patch_height, patch_width = self.flat_patch.shape[1], self.flat_patch.shape[2]\n",
    "\n",
    "        x_init_coords = torch.arange(0, self.pixel_length * patch_height, self.pixel_length)\n",
    "        y_init_coords = torch.arange(0, self.pixel_length * patch_width, self.pixel_length)\n",
    "        z_init_coords = torch.zeros((patch_height, patch_width))\n",
    "        patch_init_coords = torch.stack([\n",
    "            x_init_coords.unsqueeze(-1).broadcast_to(-1, patch_width),\n",
    "            y_init_coords.unsqueeze(0).broadcast_to(patch_height, -1),\n",
    "            z_init_coords,\n",
    "        ], dim=0)\n",
    "\n",
    "        if isinstance(self.patch_location, carla.Location):\n",
    "            x, y, z = self.patch_location.x, self.patch_location.y, self.patch_location.z\n",
    "        else:\n",
    "            x, y, z = self.patch_location[0], self.patch_location[1], self.patch_location[2]\n",
    "\n",
    "        location = torch.tensor([x, y, z]).unflatten(0, (3, 1, 1)).broadcast_to((3, patch_height, patch_width))\n",
    "\n",
    "        if isinstance(self.patch_rotation, carla.Rotation):\n",
    "            pitch, yaw, roll = self.patch_rotation.pitch, self.patch_rotation.yaw, self.patch_rotation.roll\n",
    "        else:\n",
    "            pitch, yaw, roll = self.patch_rotation[0], self.patch_rotation[1], self.patch_rotation[2]\n",
    "\n",
    "        pitch = pitch / 180.0 * math.pi\n",
    "        yaw = yaw / 180.0 * math.pi\n",
    "        roll = roll / 180.0 * math.pi\n",
    "\n",
    "        rx = torch.tensor([\n",
    "            [1, 0, 0], [0, math.cos(roll), - math.sin(roll)], [0, math.sin(roll), math.cos(roll)],\n",
    "        ], dtype=torch.float)\n",
    "        ry = torch.tensor([\n",
    "            [math.cos(pitch), 0, math.sin(pitch)], [0, 1, 0], [- math.sin(pitch), 0, math.cos(pitch)]\n",
    "        ], dtype=torch.float)\n",
    "        rz = torch.tensor([\n",
    "            [math.cos(yaw), - math.sin(yaw), 0], [math.sin(yaw),  math.cos(yaw), 0], [0, 0, 1]\n",
    "        ], dtype=torch.float)\n",
    "\n",
    "\n",
    "        coords_rotated = rz @ ry @ rx @ patch_init_coords.reshape(3, -1)\n",
    "\n",
    "        coords = coords_rotated.reshape(3, patch_height, patch_width) + location\n",
    "\n",
    "        return torch.concat([coords, torch.ones((1, patch_height, patch_width))], dim=0)\n",
    "\n",
    "    def get_patch(self):\n",
    "        \"\"\"\n",
    "        返回patch本身以及patch每个像素点的3d坐标\n",
    "        \"\"\"\n",
    "        return self.flat_patch, self.patch_pos_3d\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.get_patch()\n",
    "\n",
    "\n",
    "class CameraCallback:\n",
    "    \"\"\"\n",
    "    init_parameters:\n",
    "        rgb_camera: Sensor in carla\n",
    "        carla_patch: instance of CarlaPatch\n",
    "        output_folder_path: path of folder to save camera outputs(image format)\n",
    "    \"\"\"\n",
    "    def __init__(self, rgb_camera: carla.Sensor, camera_bp, vehicle, carla_patch: CarlaPatch, output_folder_path=None, depth_camera=None):\n",
    "        self.rgb_camera = rgb_camera\n",
    "        self.camera_bp = camera_bp\n",
    "        self.carla_patch = carla_patch\n",
    "        self.patch_data, self.patch_global_coords = self.carla_patch()\n",
    "        self.folder_path = output_folder_path\n",
    "        self.vehicle = vehicle\n",
    "\n",
    "    def _get_matrices(self, camera_data):\n",
    "        fov = self.camera_bp.get_attribute('fov').as_float()\n",
    "        focal = camera_data.width / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "        in_mat = np.identity(3)\n",
    "        in_mat[0, 0] = focal / 1.00\n",
    "        in_mat[1, 1] = focal / 1.00\n",
    "        in_mat[0, 2] = camera_data.width / 2.0\n",
    "        in_mat[1, 2] = camera_data.height / 2.0\n",
    "\n",
    "        ex_mat = self.rgb_camera.get_transform().get_inverse_matrix()\n",
    "\n",
    "        return torch.tensor(in_mat, dtype=torch.float32), torch.tensor(ex_mat)\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_raw_data(camera_data):\n",
    "        camera_data.convert(carla.ColorConverter.Raw)\n",
    "        img_tensor = torch.tensor(camera_data.raw_data, dtype=torch.uint8)\n",
    "        # convert to (c, h, w)\n",
    "        return img_tensor.reshape((camera_data.height, camera_data.width, 4))[:, :, :3].permute((2, 0, 1))\n",
    "\n",
    "    def __call__(self, camera_data: carla.Image):\n",
    "        in_mat, ex_mat = self._get_matrices(camera_data)\n",
    "\n",
    "        patch_camera_coords = (torch.tensor([[0, 1, 0, 0], [0, 0, -1, 0], [1, 0, 0.0, 0]]) @ ex_mat @ self.patch_global_coords.reshape(4, -1))[:3, :]\n",
    "\n",
    "        patch_pos2d = in_mat @ patch_camera_coords\n",
    "\n",
    "        # normalize coords\n",
    "        patch_pos2d[0] /= patch_pos2d[2]\n",
    "        patch_pos2d[1] /= patch_pos2d[2]\n",
    "\n",
    "        patch_pos2d = patch_pos2d.reshape(self.patch_data.shape)\n",
    "\n",
    "        indices = patch_pos2d[0: 2].to(torch.long)\n",
    "        # TODO: add distance mask when using depth camera\n",
    "        mask = (indices[0] >= 0) & (indices[1] >= 0) & (indices[0] < camera_data.width) & (indices[1] < camera_data.height)\n",
    "        zeros_indices = torch.zeros_like(indices[0])\n",
    "        indices = mask * indices + ~mask * zeros_indices\n",
    "\n",
    "        img_tensor = CameraCallback._convert_raw_data(camera_data)\n",
    "\n",
    "        patch_point = self.patch_global_coords[:3, 0, 0]\n",
    "        ray = carla.Location(patch_point[0].item(), patch_point[1].item(), patch_point[2].item()) - self.rgb_camera.get_transform().location\n",
    "        forward_vec = self.rgb_camera.get_transform().get_forward_vector()\n",
    "\n",
    "        if  forward_vec.dot(ray) > 0:\n",
    "            # replace pixels in camera output with patch pixels\n",
    "            img_tensor[:, indices[1], indices[0]] = (self.patch_data * 255).to(torch.uint8)\n",
    "\n",
    "        # save camera output to disk\n",
    "        cv2.imwrite(self.folder_path + f'{camera_data.frame}.jpg', img_tensor.permute(1, 2, 0).numpy())\n",
    "\n",
    "\n",
    "def get_camera2world_matrix(carla_transform: carla.Transform, real_y_axis=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        carla_transform: Carla.Transform instance, contains carla.Location and carla.Rotation\n",
    "        real_y_axis: return real y-axis value when setting true. but the view of point cloud in open-3d\n",
    "            will be reversed in yaw direction.\n",
    "    Returns:\n",
    "        a 4x4 rotation & transaction matrix that transforms coords from camera coord-sys to simu-world coord-sys.\n",
    "    \"\"\"\n",
    "    camera2vehicle_matrix = np.array([[0, 0, 1, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    pitch = carla_transform.rotation.pitch / 180.0 * math.pi\n",
    "    yaw = carla_transform.rotation.yaw / 180.0 * math.pi\n",
    "    roll = carla_transform.rotation.roll / 180.0 * math.pi\n",
    "    loc_x = carla_transform.location.x\n",
    "    loc_y = - carla_transform.location.y\n",
    "    loc_z = carla_transform.location.z\n",
    "    sin_y, sin_p, sin_r = math.sin(yaw), math.sin(pitch), math.sin(roll)\n",
    "    cos_y, cos_p, cos_r = math.cos(yaw), math.cos(pitch), math.cos(roll)\n",
    "\n",
    "    vehicle2world_matrix = np.array([\n",
    "        [cos_y * cos_p, cos_y * sin_p * sin_r + sin_y * cos_r, - cos_y * sin_p * cos_r + sin_y * sin_r, loc_x],\n",
    "        [-sin_y * cos_p, - sin_y * sin_p * sin_r + cos_y * cos_r, sin_y * sin_p * cos_r + cos_y * sin_r, loc_y],\n",
    "        [sin_p, -cos_p * sin_r, cos_p * cos_r, loc_z],\n",
    "        [0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    if real_y_axis:\n",
    "        vehicle2world_matrix[2] *= -1\n",
    "\n",
    "    return vehicle2world_matrix @ camera2vehicle_matrix\n",
    "\n",
    "\n",
    "#构造相机投影矩阵函数\n",
    "def build_projection_matrix(w, h, fov):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "    # 计算三维坐标的二维投影\n",
    "\n",
    "    # 格式化输入坐标（loc 是一个 carla.Position 对象）\n",
    "    point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "\n",
    "    # 转换到相机坐标系\n",
    "    point_camera = np.dot(w2c, point)\n",
    "\n",
    "    # 将坐标系从 UE4 的坐标系转换为标准坐标系（y, -z, x），同时移除第四个分量\n",
    "    # point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "    # 使用相机矩阵进行三维到二维投影\n",
    "    point_img = np.dot(K, point_camera[:3])\n",
    "\n",
    "    # 归一化\n",
    "    point_img[0] /= point_img[2]\n",
    "    point_img[1] /= point_img[2]\n",
    "\n",
    "    return point_img[0:2]\n",
    "\n",
    "#连接Carla并获取世界\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "\n",
    "# 生成车辆\n",
    "vehicle_bp =bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_points[0])\n",
    "print(spawn_points[0].location.x, spawn_points[0].location.y, spawn_points[0].location.z)\n",
    "\n",
    "# 生成相机\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "#生成目标车辆\n",
    "for i in range(20):\n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    if npc:\n",
    "        npc.set_autopilot(True)\n",
    "\n",
    "# 设置仿真模式为同步模式\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # 启用同步模式\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# 创建对接接收相机数据\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)\n",
    "\n",
    "# 从相机获取属性\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()  # 图像宽度\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()  # 图像高度\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()  # 视场角\n",
    "\n",
    "# 计算相机投影矩阵，用于从三维坐标投影到二维坐标\n",
    "K = build_projection_matrix(image_w, image_h, fov)\n",
    "\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "# 获取第一张图像\n",
    "world.tick()\n",
    "image = image_queue.get()\n",
    "\n",
    "# 将原始数据重新整形为 RGB 数组\n",
    "img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "# 在 OpenCV 的显示窗口中显示图像\n",
    "cv2.namedWindow('ImageWindowName', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('ImageWindowName', img)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "patch = torch.load('C:/Users/Kai/Desktop/patch.pt', map_location='cpu')\n",
    "carla_patch = CarlaPatch(patch, patch_location=(200, 100, 35), patch_rotation=(70, 60, 40), pixel_length=0.5)\n",
    "\n",
    "patch_data, coords_3d = carla_patch()\n",
    "patch_data.detach_()\n",
    "patch_data  = (patch_data * 255).to(torch.uint8)\n",
    "\n",
    "while True:\n",
    "    # 更新世界状态并获取图像\n",
    "    world.tick()\n",
    "    image = image_queue.get()\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    # img = np.flip(img,(0,))\n",
    "    # img = np.transpose(img, (1, 0, 2))\n",
    "\n",
    "    transform = camera.get_transform()\n",
    "\n",
    "    # point = coords_3d.reshape(4, -1).numpy()\n",
    "    # # 转换到相机坐标系\n",
    "    #\n",
    "    # point_camera = (np.linalg.inv(get_camera2world_matrix(transform, real_y_axis=True)) @ point)[:3]\n",
    "    # # 将坐标系从 UE4 的坐标系转换为标准坐标系（y, -z, x），同时移除第四个分量\n",
    "    # # point_camera = [point_camera[1], point_camera[2], point_camera[0]]\n",
    "    # # 使用相机矩阵进行三维到二维投影\n",
    "    # point_img = K @ point_camera\n",
    "    # point_img[0] /= point_img[2]\n",
    "    # point_img[1] /= point_img[2]\n",
    "    #\n",
    "    #\n",
    "    # point_img = np.array(point_img[0:2].reshape(2, 128, 128), dtype=np.int64)\n",
    "    # mask = (point_img[0] >= 0) & (point_img[1] >= 0) & (point_img[0] < 800) & (point_img[1] < 600)\n",
    "    # zeros_indices = np.zeros_like(point_img[0])\n",
    "    # point_img = mask * point_img + ~mask * zeros_indices\n",
    "    #\n",
    "    # ray = carla.Location(coords_3d[:3, 0, 0][0].item(), coords_3d[:3, 0, 0][1].item(), coords_3d[:3, 0, 0][2].item()) - vehicle.get_transform().location\n",
    "    # forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "    #\n",
    "    # if  forward_vec.dot(ray) > 1:\n",
    "    #     # replace pixels in camera output with patch pixels\n",
    "    #     img[point_img[0], point_img[1], :3] = patch_data.permute((1, 2, 0)).numpy()\n",
    "\n",
    "    # for loop format\n",
    "    #\n",
    "    # for i in range(128):\n",
    "    #     for j in range(128):\n",
    "    #         posi = coords_3d[:, i, j]\n",
    "    #         p = get_image_point(carla.Location(posi[0].item(), posi[1].item(), posi[2].item()), K, world_2_camera)\n",
    "    #         if 0 <= p[0] < 600 and 0 <= p[1] < 800:\n",
    "    #             img[int(p[1]), int(p[0]), :3] = patch_data[:, i, j].numpy()\n",
    "\n",
    "    world_2_camera = np.linalg.inv(get_camera2world_matrix(transform, real_y_axis=False))\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "        # 过滤掉自车\n",
    "        if npc.id != vehicle.id:\n",
    "            bb = npc.bounding_box\n",
    "            dist = npc.get_transform().location.distance(vehicle.get_transform().location)\n",
    "\n",
    "            # 筛选距离在50米以内的车辆\n",
    "            if dist < 50:\n",
    "                forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "                ray = npc.get_transform().location - vehicle.get_transform().location\n",
    "\n",
    "                # 计算车辆前进方向与车辆之间的向量的点积，\n",
    "                # 通过阈值判断是否在相机前方绘制边界框\n",
    "                if forward_vec.dot(ray) > 1:\n",
    "\n",
    "                    p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "\n",
    "                    for edge in edges:\n",
    "                        # print('bb location', (verts[edge[0]].x, verts[edge[0]].y, verts[edge[0]].z))\n",
    "                        # print('self location:', vehicle.get_transform().location.x, vehicle.get_transform().location.y, vehicle.get_transform().location.z)\n",
    "                        p1 = get_image_point(verts[edge[0]], K, world_2_camera)\n",
    "                        p2 = get_image_point(verts[edge[1]], K, world_2_camera)\n",
    "                        cv2.line(img, (int(p1[0]), int(p1[1])), (int(p2[0]), int(p2[1])), (255, 0, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow('ImageWindowName', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "settings.synchronous_mode = False\n",
    "world.apply_settings(settings)\n",
    "camera.destroy()\n",
    "image_queue.queue.clear()\n",
    "vehicle.destroy()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([187.9101, 176.3473, -10.7102,   1.0000])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_3d[:, 127, 127]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "285"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_img[:, 100].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patch = torch.load('C:/Users/Kai/Desktop/patch.pt', map_location='cpu')\n",
    "carla_patch = CarlaPatch(patch, patch_location=(-64, -24, 10), patch_rotation=(70, 60, 40), pixel_length=0.8)\n",
    "\n",
    "patch_data, coords_3d = carla_patch()\n",
    "coords_3d[:, 0, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "# from utils.utils import *\n",
    "# from utils.visualize_utils import *\n",
    "import random\n",
    "import carla\n",
    "# from carla_patch import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(500.0)\n",
    "world = client.get_world()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "spawnpoints = world.get_map().get_spawn_points()\n",
    "spectator = world.get_spectator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sp = spawnpoints[0]\n",
    "(sp.location.x, sp.location.y, sp.location.z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vehicle_blueprint = blueprint_library.find('vehicle.audi.etron')\n",
    "#Fahrzeug wird an einem zufälligen Spawnpunkt gespawnt\n",
    "vehicle = world.try_spawn_actor(vehicle_blueprint, spawnpoints[0])\n",
    "vehicle.set_autopilot(True)\n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-2,z=1.5)),vehicle.get_transform().rotation)\n",
    "spectator.set_transform(transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# settings = world.get_settings()\n",
    "# settings.synchronous_mode = True # 启用同步模式\n",
    "# settings.fixed_delta_seconds = 0.05\n",
    "# world.apply_settings(settings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camera_blueprint = blueprint_library.find('sensor.camera.rgb')\n",
    "# camera_blueprint.set_attribute('focal_distance', '1000')\n",
    "camera_transform = carla.Transform(carla.Location(z=2,x=0.5))\n",
    "camera = world.spawn_actor(camera_blueprint,camera_transform,attach_to=vehicle)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patch = torch.load('C:/Users/Kai/Desktop/patch.pt', map_location='cpu')\n",
    "carla_patch = CarlaPatch(patch, patch_location=(200, -250, 16), patch_rotation=(70, 60, 40), pixel_length=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camera_callback = CameraCallback(camera, camera_blueprint, vehicle, carla_patch, output_folder_path='C:/Users/Kai/Desktop/frames/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camera.listen(lambda image: camera_callback(image))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camera.destroy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_matrices(camera_bp, rgb_camera):\n",
    "    fov = camera_bp.get_attribute('fov').as_float()\n",
    "    focal = camera_blueprint.get_attribute('image_size_x').as_int() / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    in_mat = np.identity(3)\n",
    "    in_mat[0, 0] = focal / 1.00\n",
    "    in_mat[1, 1] = focal / 1.00\n",
    "    in_mat[0, 2] = camera_blueprint.get_attribute('image_size_x').as_int() / 2.0\n",
    "    in_mat[1, 2] = camera_blueprint.get_attribute('image_size_y').as_int() / 2.0\n",
    "\n",
    "    ex_mat = rgb_camera.get_transform().get_inverse_matrix()\n",
    "\n",
    "    return torch.tensor(in_mat, dtype=torch.float32), torch.tensor(ex_mat)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vehicle.set_autopilot(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "in_mat, ex_mat = _get_matrices(camera_blueprint, camera)\n",
    "camera.get_transform().location.x, camera.get_transform().location.y, camera.get_transform().location.z"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coords_camera = ex_mat @ torch.tensor([-100.0, 75, 2, 1])\n",
    "coords_camera"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "swap_axis_coords = torch.tensor([coords_camera[1], - coords_camera[2], coords_camera[0]])\n",
    "swap_axis_coords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coords_pix = (in_mat @ swap_axis_coords)\n",
    "coords_pix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coords_pix[0] /= coords_pix[2]\n",
    "coords_pix[1] /= coords_pix[2]\n",
    "coords_pix.to(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils')\n",
    "from utils.visualize_utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patch = torch.load('C:/Users/Kai/Desktop/patch.pt', map_location='cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show(patch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show(patch.transpose(1, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show(transforms.RandomVerticalFlip(p=1)(transforms.RandomHorizontalFlip(p=1)(patch)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.ndarray((600, 800, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.flip(array, axis=(1)).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "array[-3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
